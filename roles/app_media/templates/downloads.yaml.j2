---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: downloads
  namespace: {{ media_namespace }}
  labels:
    app.kubernetes.io/name: downloads
    app.kubernetes.io/instance: downloads
    app.kubernetes.io/part-of: media
    app.kubernetes.io/component: downloads
    app.kubernetes.io/managed-by: ansible
  annotations:
    app.kubernetes.io/description: "Download stack with Mullvad VPN protection"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: downloads
      app.kubernetes.io/instance: downloads
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: downloads
        app.kubernetes.io/instance: downloads
        app.kubernetes.io/part-of: media
        app.kubernetes.io/component: downloads
        app.kubernetes.io/managed-by: ansible
    spec:
{% if downloads_node_selector is defined and downloads_node_selector %}
      nodeSelector:
{% for key, value in downloads_node_selector.items() %}
        {{ key }}: "{{ value }}"
{% endfor %}
{% endif %}
      containers:
        # Gluetun VPN container - all traffic routes through this
        - name: gluetun
          image: qmcgaw/gluetun:{{ gluetun_version }}
          lifecycle:
            postStart:
              exec:
                command: ["/bin/sh", "-c", "(ip rule del table 51820; ip -6 rule del table 51820) || true"]
          securityContext:
            capabilities:
              add:
                - NET_ADMIN
            runAsUser: 0
          env:
            - name: VPN_SERVICE_PROVIDER
              value: "mullvad"
            - name: VPN_TYPE
              value: "wireguard"
            - name: WIREGUARD_PRIVATE_KEY
              valueFrom:
                secretKeyRef:
                  name: downloads-vpn-secrets
                  key: WIREGUARD_PRIVATE_KEY
            - name: WIREGUARD_ADDRESSES
              valueFrom:
                secretKeyRef:
                  name: downloads-vpn-secrets
                  key: WIREGUARD_ADDRESSES
{% if gluetun_server_cities is defined and gluetun_server_cities %}
            - name: SERVER_CITIES
              value: "{{ gluetun_server_cities }}"
{% endif %}
{% if gluetun_server_countries is defined and gluetun_server_countries %}
            - name: SERVER_COUNTRIES
              value: "{{ gluetun_server_countries }}"
{% endif %}
{% if gluetun_server_hostnames is defined and gluetun_server_hostnames %}
            - name: SERVER_HOSTNAMES
              value: "{{ gluetun_server_hostnames }}"
{% endif %}
{% if gluetun_wireguard_endpoint_port is defined and gluetun_wireguard_endpoint_port %}
            - name: WIREGUARD_ENDPOINT_PORT
              value: "{{ gluetun_wireguard_endpoint_port }}"
{% endif %}
            - name: TZ
              value: "{{ media_timezone }}"
            - name: FIREWALL_VPN_INPUT_PORTS
              value: "{{ gluetun_firewall_input_ports }}"
            - name: FIREWALL_OUTBOUND_SUBNETS
              value: "{{ gluetun_firewall_outbound_subnets }}"
            # Use K8s DNS instead of Gluetun's loopback DNS server
            # Required workaround for musl libc bug in Alpine-based containers
            # Note: DNS queries go through cluster DNS (not VPN), but all other
            # traffic is VPN-protected. This is an acceptable tradeoff.
            - name: DNS_KEEP_NAMESERVER
              value: "on"
          ports:
            - containerPort: 8000
              name: gluetun-http
              protocol: TCP
            - containerPort: 8080
              name: qbit-http
              protocol: TCP
            - containerPort: 9117
              name: jackett-http
              protocol: TCP
            - containerPort: 8191
              name: flare-http
              protocol: TCP
            - containerPort: 8085
              name: sabnzbd-http
              protocol: TCP
          resources:
            requests:
              cpu: {{ gluetun_cpu_request }}
              memory: {{ gluetun_memory_request }}
            limits:
              cpu: {{ gluetun_cpu_limit }}
              memory: {{ gluetun_memory_limit }}
          livenessProbe:
            tcpSocket:
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            tcpSocket:
              port: 8000
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
        # qBittorrent download client container
        - name: qbittorrent
          image: linuxserver/qbittorrent:{{ qbittorrent_version }}
          lifecycle:
            postStart:
              exec:
                command: ["/bin/sh", "-c", "sleep 15"]
          env:
            - name: PUID
              value: "{{ media_puid }}"
            - name: PGID
              value: "{{ media_pgid }}"
            - name: TZ
              value: "{{ media_timezone }}"
            - name: WEBUI_PORT
              value: "8080"
          resources:
            requests:
              cpu: {{ qbittorrent_cpu_request }}
              memory: {{ qbittorrent_memory_request }}
            limits:
              cpu: {{ qbittorrent_cpu_limit }}
              memory: {{ qbittorrent_memory_limit }}
          volumeMounts:
            - name: qbittorrent-config
              mountPath: /config
            - name: media
              mountPath: /media
          livenessProbe:
            httpGet:
              path: /
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
        # Jackett indexer manager container
        - name: jackett
          image: linuxserver/jackett:{{ jackett_version }}
          env:
            - name: PUID
              value: "{{ media_puid }}"
            - name: PGID
              value: "{{ media_pgid }}"
            - name: TZ
              value: "{{ media_timezone }}"
            - name: AUTO_UPDATE
              value: "true"
          resources:
            requests:
              cpu: {{ jackett_cpu_request }}
              memory: {{ jackett_memory_request }}
            limits:
              cpu: {{ jackett_cpu_limit }}
              memory: {{ jackett_memory_limit }}
          volumeMounts:
            - name: jackett-config
              mountPath: /config
          readinessProbe:
            tcpSocket:
              port: 9117
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
        # FlareSolverr proxy container (handles Cloudflare-protected sites)
        - name: flaresolver
          image: flaresolverr/flaresolverr:{{ flaresolverr_version }}
          env:
            - name: LOG_LEVEL
              value: info
            - name: HEADLESS
              value: "true"
          resources:
            requests:
              cpu: {{ flaresolverr_cpu_request }}
              memory: {{ flaresolverr_memory_request }}
            limits:
              cpu: {{ flaresolverr_cpu_limit }}
              memory: {{ flaresolverr_memory_limit }}
          livenessProbe:
            httpGet:
              path: /
              port: 8191
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /
              port: 8191
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
        # SABnzbd Usenet download client container
        - name: sabnzbd
          image: linuxserver/sabnzbd:{{ sabnzbd_version }}
          env:
            - name: PUID
              value: "{{ media_puid }}"
            - name: PGID
              value: "{{ media_pgid }}"
            - name: TZ
              value: "{{ media_timezone }}"
          resources:
            requests:
              cpu: {{ sabnzbd_cpu_request }}
              memory: {{ sabnzbd_memory_request }}
            limits:
              cpu: {{ sabnzbd_cpu_limit }}
              memory: {{ sabnzbd_memory_limit }}
          volumeMounts:
            - name: sabnzbd-config
              mountPath: /config
            - name: media
              mountPath: /media
          # No liveness probe - SABnzbd becomes unresponsive during heavy
          # download/unpack operations which would cause unnecessary restarts
          readinessProbe:
            httpGet:
              path: /
              port: 8085
            initialDelaySeconds: 30
            periodSeconds: 15
            timeoutSeconds: 10
            failureThreshold: 6
      volumes:
        - name: qbittorrent-config
          persistentVolumeClaim:
            claimName: qbittorrent-config-pvc
        - name: jackett-config
          persistentVolumeClaim:
            claimName: jackett-config-pvc
        - name: sabnzbd-config
          persistentVolumeClaim:
            claimName: sabnzbd-config-pvc
        - name: media
          persistentVolumeClaim:
            claimName: sonarr-media-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: downloads
  namespace: {{ media_namespace }}
  labels:
    app.kubernetes.io/name: downloads
    app.kubernetes.io/instance: downloads
    app.kubernetes.io/part-of: media
    app.kubernetes.io/component: downloads
    app.kubernetes.io/managed-by: ansible
  annotations:
    app.kubernetes.io/description: "Download stack service"
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: 8000
      protocol: TCP
      name: gluetun
    - port: 8080
      targetPort: 8080
      protocol: TCP
      name: qbittorrent
    - port: 9117
      targetPort: 9117
      protocol: TCP
      name: jackett
    - port: 8191
      targetPort: 8191
      protocol: TCP
      name: flaresolver
    - port: 8085
      targetPort: 8085
      protocol: TCP
      name: sabnzbd
  selector:
    app.kubernetes.io/name: downloads
    app.kubernetes.io/instance: downloads
